#!/usr/bin/env python3
"""Llama-MoE í”„ë¡œì íŠ¸ ì „ì—­ì—ì„œ ì‚¬ìš©í•˜ëŠ” ìœ í‹¸ë¦¬í‹° ëª¨ìŒ."""

import os
import yaml
import logging
import torch
import gc
import json
import shutil
from datetime import datetime
from typing import Dict, Any, List, Optional
import random
import numpy as np

# Import from unified config
from config.domains import domain_manager

def setup_logging(log_file: str = None, level: str = "INFO"):
    """ê³µí†µ ë¡œê¹… ì„¤ì •ì„ ì´ˆê¸°í™”í•œë‹¤."""
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    
    handlers = [logging.StreamHandler()]
    if log_file:
        os.makedirs(os.path.dirname(log_file), exist_ok=True)
        handlers.append(logging.FileHandler(log_file))
    
    logging.basicConfig(
        level=getattr(logging, level.upper()),
        format=log_format,
        handlers=handlers
    )

def print_gpu_memory_summary(stage: str = ""):
    """GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ìš”ì•½í•´ ì¶œë ¥í•œë‹¤. -> ë©”ëª¨ë¦¬ ì²´í‚¹ìš© ì•ˆí•˜ë©´ ë„ê¸°"""
    if not torch.cuda.is_available():
        print(f"[GPU] {stage}: CUDA not available")
        return
    
    try:
        for i in range(torch.cuda.device_count()):
            total = torch.cuda.get_device_properties(i).total_memory / 1024**3
            allocated = torch.cuda.memory_allocated(i) / 1024**3
            reserved = torch.cuda.memory_reserved(i) / 1024**3
            max_allocated = torch.cuda.max_memory_allocated(i) / 1024**3
            free = total - reserved
            
            print(f"[GPU{i}] {stage}: mem: alloc={allocated:.2f} GiB, "
                  f"reserved={reserved:.2f} GiB, max_alloc={max_allocated:.2f} GiB, "
                  f"free={free:.2f} GiB/ total={total:.2f} GiB")
    except Exception as e:
        print(f"[GPU] {stage}: Error getting memory info - {e}")

def clear_gpu_memory():
    """GPU ìºì‹œì™€ íŒŒì´ì¬ GCë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì •ë¦¬í•œë‹¤."""
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
    gc.collect()

def validate_environment() -> bool:
    """í•™ìŠµì— í•„ìš”í•œ í™˜ê²½(CUDA, GPU)ì„ ê²€ì¦í•œë‹¤."""
    try:
        # Check CUDA availability
        if not torch.cuda.is_available():
            print("âŒ CUDA not available")
            return False
        
        # Check GPU memory
        gpu_count = torch.cuda.device_count()
        if gpu_count == 0:
            print("âŒ No GPU devices found")
            return False
        
        print(f"âœ… Found {gpu_count} GPU device(s)")
        for i in range(gpu_count):
            props = torch.cuda.get_device_properties(i)
            print(f"GPU {i}: {props.name} ({props.total_memory / 1024**3:.1f} GB)")
        
        return True
    except Exception as e:
        print(f"âŒ Environment validation failed: {e}")
        return False

def setup_cuda_environment():
    """ì„¤ì • íŒŒì¼ì„ ì°¸ì¡°í•´ CUDA í™˜ê²½ ë³€ìˆ˜ë¥¼ êµ¬ì„±í•œë‹¤."""
    from config.moe import get_gpu_config
    
    gpu_config = get_gpu_config()
    os.environ["CUDA_VISIBLE_DEVICES"] = gpu_config.cuda_visible_devices
    
    print(f"ğŸ® CUDA_VISIBLE_DEVICES set to: {gpu_config.cuda_visible_devices}")

def setup_random_seed(seed: int = None):
    """ì¬í˜„ì„±ì„ ìœ„í•´ ëœë¤ ì‹œë“œë¥¼ ì„¤ì •í•œë‹¤."""
    if seed is None:
        from config.moe import get_system_config
        system_config = get_system_config()
        seed = system_config.seed
    
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    
    # Enable deterministic behavior
    torch.backends.cudnn.deterministic = False
    torch.backends.cudnn.benchmark = False
    
    print(f"ğŸ² Random seed set to: {seed}")

def load_config(config_path: str) -> Dict[str, Any]:
    """YAML êµ¬ì„± íŒŒì¼ì„ ë¡œë“œí•œë‹¤."""
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        return config
    except Exception as e:
        print(f"âŒ Failed to load config from {config_path}: {e}")
        raise

def check_data_availability(domains: List[str] = None) -> Dict[str, bool]:
    """ë„ë©”ì¸ë³„ ë°ì´í„° ì¡´ì¬ ì—¬ë¶€ë¥¼ ë°˜í™˜í•œë‹¤."""
    if domains is None:
        domains = domain_manager.get_available_domains()
    
    availability = {}
    for domain in domains:
        try:
            domain_availability = domain_manager.check_data_availability(domain)
            availability[domain] = domain_availability[domain]
        except Exception as e:
            print(f"âš ï¸ Error checking {domain} data: {e}")
            availability[domain] = False
    
    return availability

def save_config_to_output_dir(config_path: str, output_dir: str, config_name: str = "config.yaml"):
    """ì‚¬ìš©í•œ ì„¤ì • íŒŒì¼ì„ ì¶œë ¥ ë””ë ‰í„°ë¦¬ì— ë³µì‚¬í•œë‹¤."""
    try:
        # Ensure output directory exists
        os.makedirs(output_dir, exist_ok=True)
        
        # Copy config file to output directory
        destination_path = os.path.join(output_dir, config_name)
        shutil.copy2(config_path, destination_path)
        
        print(f"ğŸ“ Config file saved to: {destination_path}")
        return destination_path
    except Exception as e:
        print(f"âŒ Failed to save config file: {e}")
        return None
